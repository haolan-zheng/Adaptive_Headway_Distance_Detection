{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dd0c1-b235-4798-9a56-87c527068002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adaptive Vehicle Detection and Distance Estimation System\n",
    "=========================================================\n",
    "\n",
    "A real-time vehicle detection system using dual YOLO models (license plate + vehicle detection)\n",
    "with adaptive car width learning for improved distance estimation accuracy.\n",
    "\n",
    "Features:\n",
    "- Hybrid detection: License plate (near) + vehicle body (far)\n",
    "- Adaptive car width learning from detected license plates\n",
    "- Multi-filter system: oncoming traffic, crossing traffic, distance jumps\n",
    "- Vehicle tracking with unique IDs\n",
    "- Minimum 2-second dwell time filter\n",
    "- Cross-platform GPU support (CUDA for NVIDIA, MPS for Apple Silicon)\n",
    "\n",
    "Requirements:\n",
    "- Python 3.8+\n",
    "- PyTorch (with CUDA support for NVIDIA GPUs)\n",
    "- ultralytics (YOLOv8)\n",
    "- OpenCV\n",
    "- NumPy\n",
    "- pandas\n",
    "\n",
    "Author: Haolan Zheng\n",
    "License: MIT\n",
    "\"\"\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "\n",
    "# Model paths\n",
    "PLATE_MODEL_PATH = '/Users/haolanzheng/Documents/AI/Plate_Detection/models/training_runs/license_plate_detector_v1/weights/best.pt'\n",
    "VEHICLE_MODEL_PATH = 'yolov8n.pt'\n",
    "\n",
    "# Video paths\n",
    "VIDEO_INPUT = '/Volumes/Haolan/AI_Archive/Plate_Detection/source_videos/day_combined.mp4'\n",
    "OUTPUT_DIR = Path('/Volumes/Haolan/AI_Archive/Plate_Detection/output_videos')\n",
    "CSV_DIR = Path('/Volumes/Haolan/AI_Archive/Plate_Detection/output_csv')\n",
    "\n",
    "# Distance estimation parameters\n",
    "REAL_PLATE_WIDTH_CM = 30.5\n",
    "FOCAL_LENGTH_PIXELS = 577\n",
    "DISTANCE_THRESHOLD = 6.0  # Switch from plate to car detection beyond this distance\n",
    "\n",
    "# Adaptive car sizing\n",
    "DEFAULT_CAR_WIDTH_CM = 180\n",
    "MIN_CAR_WIDTH_CM = 150\n",
    "MAX_CAR_WIDTH_CM = 220\n",
    "MAX_WIDTH_HISTORY = 10\n",
    "\n",
    "# Vehicle tracking\n",
    "VEHICLE_TIMEOUT_FRAMES = 30\n",
    "MIN_DWELL_FRAMES = 60  # 2 seconds at 30fps - minimum consecutive frames to display\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "# Filter thresholds\n",
    "CROSSING_DETECTION_FRAMES = 10\n",
    "HORIZONTAL_TO_VERTICAL_RATIO = 2.0\n",
    "MIN_HORIZONTAL_MOVEMENT_PIXELS = 150\n",
    "\n",
    "DIRECTION_CHECK_FRAMES = 5\n",
    "SIZE_INCREASE_THRESHOLD = 1.15\n",
    "Y_MOVEMENT_THRESHOLD = 30\n",
    "ONCOMING_MIN_DISTANCE = 6.0  # Don't apply oncoming filter if vehicle < 6m\n",
    "\n",
    "DISTANCE_JUMP_THRESHOLD = 8.0  # Maximum distance change per frame (meters)\n",
    "\n",
    "# ROI configuration (trapezoid shape for lane focus)\n",
    "ROI_TOP_LEFT_X_RATIO = 0.44\n",
    "ROI_TOP_RIGHT_X_RATIO = 0.46\n",
    "ROI_BOTTOM_LEFT_X_RATIO = 0.33\n",
    "ROI_BOTTOM_RIGHT_X_RATIO = 0.59\n",
    "ROI_TOP_Y_RATIO = 0.60\n",
    "ROI_BOTTOM_Y_RATIO = 0.90\n",
    "\n",
    "# Multi-vehicle priority\n",
    "ROI_BOTTOM_PRIORITY_RATIO = 0.7  # Prioritize vehicles in bottom 70% of ROI\n",
    "\n",
    "# ==================== INITIALIZATION ====================\n",
    "\n",
    "print(\"Adaptive Vehicle Detection System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Auto-detect best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"Device: CUDA (NVIDIA GPU)\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"Device: MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"Device: CPU (No GPU acceleration)\")\n",
    "    print(\"Warning: Processing will be slower without GPU acceleration\")\n",
    "\n",
    "# Load models\n",
    "plate_model = YOLO(PLATE_MODEL_PATH)\n",
    "vehicle_model = YOLO(VEHICLE_MODEL_PATH)\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_video_path = str(OUTPUT_DIR / f\"vehicle_detection_{timestamp}.mp4\")\n",
    "output_csv_path = str(CSV_DIR / f\"distance_data_{timestamp}.csv\")\n",
    "\n",
    "print(f\"Input: {VIDEO_INPUT}\")\n",
    "print(f\"Output Video: {output_video_path}\")\n",
    "print(f\"Output CSV: {output_csv_path}\")\n",
    "print()\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(VIDEO_INPUT)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Calculate ROI points\n",
    "roi_points = np.array([\n",
    "    [int(frame_width * ROI_TOP_LEFT_X_RATIO), int(frame_height * ROI_TOP_Y_RATIO)],\n",
    "    [int(frame_width * ROI_TOP_RIGHT_X_RATIO), int(frame_height * ROI_TOP_Y_RATIO)],\n",
    "    [int(frame_width * ROI_BOTTOM_RIGHT_X_RATIO), int(frame_height * ROI_BOTTOM_Y_RATIO)],\n",
    "    [int(frame_width * ROI_BOTTOM_LEFT_X_RATIO), int(frame_height * ROI_BOTTOM_Y_RATIO)]\n",
    "], np.int32)\n",
    "\n",
    "# Video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(f\"Video: {frame_width}x{frame_height} @ {fps}fps\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Focal length: {FOCAL_LENGTH_PIXELS}px\")\n",
    "print(f\"Minimum dwell time: {MIN_DWELL_FRAMES} frames ({MIN_DWELL_FRAMES/fps:.1f}s)\")\n",
    "print()\n",
    "\n",
    "# ==================== CLASSES ====================\n",
    "\n",
    "class DistanceTracker:\n",
    "    \"\"\"Tracks vehicle distance and movement patterns over time\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history=15):\n",
    "        self.distance_history = deque(maxlen=max_history)\n",
    "        self.position_history = deque(maxlen=max_history)\n",
    "        self.x_positions = deque(maxlen=CROSSING_DETECTION_FRAMES)\n",
    "        self.y_positions = deque(maxlen=CROSSING_DETECTION_FRAMES)\n",
    "        self.bbox_areas = deque(maxlen=DIRECTION_CHECK_FRAMES)\n",
    "        self.calibrated_widths = deque(maxlen=MAX_WIDTH_HISTORY)\n",
    "        self.last_bbox = None\n",
    "        self.last_distance = None\n",
    "        self.consecutive_frames = 0\n",
    "        \n",
    "    def update(self, distance, position, detected, car_width_cm=None):\n",
    "        \"\"\"Update tracker with new detection data\"\"\"\n",
    "        if detected:\n",
    "            self.distance_history.append(distance)\n",
    "            self.position_history.append(position)\n",
    "            self.consecutive_frames += 1\n",
    "            self.last_bbox = position\n",
    "            self.last_distance = distance\n",
    "            \n",
    "            if position:\n",
    "                x_center = (position[0] + position[2]) / 2\n",
    "                y_center = (position[1] + position[3]) / 2\n",
    "                self.x_positions.append(x_center)\n",
    "                self.y_positions.append(y_center)\n",
    "                \n",
    "                bbox_area = (position[2] - position[0]) * (position[3] - position[1])\n",
    "                self.bbox_areas.append(bbox_area)\n",
    "            \n",
    "            if car_width_cm and MIN_CAR_WIDTH_CM <= car_width_cm <= MAX_CAR_WIDTH_CM:\n",
    "                self.calibrated_widths.append(car_width_cm)\n",
    "        else:\n",
    "            self.consecutive_frames = 0\n",
    "    \n",
    "    def check_distance_jump(self, new_distance):\n",
    "        \"\"\"Detect abnormal distance changes indicating tracking errors\"\"\"\n",
    "        if self.last_distance is None:\n",
    "            return False\n",
    "        return abs(new_distance - self.last_distance) > DISTANCE_JUMP_THRESHOLD\n",
    "    \n",
    "    def is_approaching(self):\n",
    "        \"\"\"Detect oncoming traffic (size increasing + moving down in frame)\"\"\"\n",
    "        if len(self.bbox_areas) < DIRECTION_CHECK_FRAMES or len(self.y_positions) < DIRECTION_CHECK_FRAMES:\n",
    "            return False\n",
    "        \n",
    "        areas_list = list(self.bbox_areas)\n",
    "        first_area = areas_list[0]\n",
    "        last_area = areas_list[-1]\n",
    "        size_increased = first_area > 0 and (last_area / first_area) > SIZE_INCREASE_THRESHOLD\n",
    "        \n",
    "        y_positions_list = list(self.y_positions)\n",
    "        first_y = y_positions_list[0]\n",
    "        last_y = y_positions_list[-1]\n",
    "        moved_down = (last_y - first_y) > Y_MOVEMENT_THRESHOLD\n",
    "        \n",
    "        return size_increased and moved_down\n",
    "    \n",
    "    def is_crossing_traffic(self):\n",
    "        \"\"\"Detect crossing traffic (horizontal movement)\"\"\"\n",
    "        if len(self.x_positions) < CROSSING_DETECTION_FRAMES or len(self.y_positions) < CROSSING_DETECTION_FRAMES:\n",
    "            return False\n",
    "        \n",
    "        x_positions_list = list(self.x_positions)\n",
    "        y_positions_list = list(self.y_positions)\n",
    "        \n",
    "        horizontal_movement = max(x_positions_list) - min(x_positions_list)\n",
    "        vertical_movement = max(y_positions_list) - min(y_positions_list)\n",
    "        \n",
    "        ratio_check = vertical_movement > 0 and horizontal_movement / vertical_movement > HORIZONTAL_TO_VERTICAL_RATIO\n",
    "        absolute_check = horizontal_movement > MIN_HORIZONTAL_MOVEMENT_PIXELS\n",
    "        \n",
    "        return ratio_check and absolute_check\n",
    "    \n",
    "    def get_smoothed_distance(self):\n",
    "        \"\"\"Calculate exponentially weighted average of distance history\"\"\"\n",
    "        if len(self.distance_history) == 0:\n",
    "            return None\n",
    "        weights = np.exp(np.linspace(-1, 0, len(self.distance_history)))\n",
    "        weights /= weights.sum()\n",
    "        return np.average(list(self.distance_history), weights=weights)\n",
    "    \n",
    "    def get_calibrated_car_width(self):\n",
    "        \"\"\"Get learned car width or use default\"\"\"\n",
    "        if len(self.calibrated_widths) > 0:\n",
    "            return np.median(list(self.calibrated_widths))\n",
    "        return DEFAULT_CAR_WIDTH_CM\n",
    "\n",
    "# ==================== HELPER FUNCTIONS ====================\n",
    "\n",
    "def check_in_roi(x_center, y_center):\n",
    "    \"\"\"Check if point is inside trapezoid ROI\"\"\"\n",
    "    roi_top_y = int(frame_height * ROI_TOP_Y_RATIO)\n",
    "    roi_bottom_y = int(frame_height * ROI_BOTTOM_Y_RATIO)\n",
    "    roi_top_left_x = int(frame_width * ROI_TOP_LEFT_X_RATIO)\n",
    "    roi_top_right_x = int(frame_width * ROI_TOP_RIGHT_X_RATIO)\n",
    "    roi_bottom_left_x = int(frame_width * ROI_BOTTOM_LEFT_X_RATIO)\n",
    "    roi_bottom_right_x = int(frame_width * ROI_BOTTOM_RIGHT_X_RATIO)\n",
    "    \n",
    "    if roi_top_y <= y_center <= roi_bottom_y:\n",
    "        ratio = (y_center - roi_top_y) / (roi_bottom_y - roi_top_y)\n",
    "        left_bound = roi_top_left_x + ratio * (roi_bottom_left_x - roi_top_left_x)\n",
    "        right_bound = roi_top_right_x + ratio * (roi_bottom_right_x - roi_top_right_x)\n",
    "        return left_bound <= x_center <= right_bound\n",
    "    return False\n",
    "\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    \"\"\"Calculate Intersection over Union for two bounding boxes\"\"\"\n",
    "    x1_1, y1_1, x2_1, y2_1 = bbox1\n",
    "    x1_2, y1_2, x2_2, y2_2 = bbox2\n",
    "    \n",
    "    xi1 = max(x1_1, x1_2)\n",
    "    yi1 = max(y1_1, y1_2)\n",
    "    xi2 = min(x2_1, x2_2)\n",
    "    yi2 = min(y2_1, y2_2)\n",
    "    \n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# ==================== MAIN PROCESSING LOOP ====================\n",
    "\n",
    "tracked_vehicles = {}\n",
    "next_vehicle_id = 1\n",
    "current_vehicle_id = None\n",
    "last_seen_frame = {}\n",
    "frame_count = 0\n",
    "\n",
    "# CSV data storage\n",
    "csv_data = []\n",
    "\n",
    "print(\"Processing video...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Progress indicator\n",
    "    if frame_count % 500 == 0:\n",
    "        progress = frame_count / total_frames * 100\n",
    "        vehicle_status = f\"Vehicle #{current_vehicle_id}\" if current_vehicle_id else \"No vehicle\"\n",
    "        print(f\"Frame {frame_count}/{total_frames} ({progress:.1f}%) | {vehicle_status}\")\n",
    "    \n",
    "    display_frame = frame.copy()\n",
    "    cv2.polylines(display_frame, [roi_points], True, (255, 255, 0), 2)\n",
    "    \n",
    "    # Timeout check - remove vehicles not seen recently\n",
    "    vehicles_to_remove = []\n",
    "    for vid in list(tracked_vehicles.keys()):\n",
    "        if frame_count - last_seen_frame.get(vid, 0) > VEHICLE_TIMEOUT_FRAMES:\n",
    "            vehicles_to_remove.append(vid)\n",
    "            if vid == current_vehicle_id:\n",
    "                current_vehicle_id = None\n",
    "    \n",
    "    for vid in vehicles_to_remove:\n",
    "        del tracked_vehicles[vid]\n",
    "        if vid in last_seen_frame:\n",
    "            del last_seen_frame[vid]\n",
    "    \n",
    "    # STEP 1: Detect license plates\n",
    "    plate_results = plate_model(frame, conf=0.20, verbose=False, device=device)\n",
    "    \n",
    "    plate_detected = False\n",
    "    plate_distance = None\n",
    "    plate_box = None\n",
    "    \n",
    "    for box in plate_results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        x_center = (x1 + x2) / 2\n",
    "        y_center = (y1 + y2) / 2\n",
    "        \n",
    "        if check_in_roi(x_center, y_center):\n",
    "            plate_width_pixels = abs(x2 - x1)\n",
    "            if plate_width_pixels > 0:\n",
    "                distance_cm = (REAL_PLATE_WIDTH_CM * FOCAL_LENGTH_PIXELS) / plate_width_pixels\n",
    "                plate_distance = distance_cm / 100\n",
    "                plate_box = (x1, y1, x2, y2)\n",
    "                plate_detected = True\n",
    "                break\n",
    "    \n",
    "    # STEP 2: Detect vehicles in ROI\n",
    "    vehicle_results = vehicle_model(frame, classes=[2], conf=0.30, verbose=False, device=device)\n",
    "    \n",
    "    vehicle_detections = []\n",
    "    for box in vehicle_results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        x_center = (x1 + x2) / 2\n",
    "        y_center = (y1 + y2) / 2\n",
    "        \n",
    "        if check_in_roi(x_center, y_center):\n",
    "            car_width_px = abs(x2 - x1)\n",
    "            bbox_area = car_width_px * abs(y2 - y1)\n",
    "            \n",
    "            vehicle_detections.append({\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'area': bbox_area,\n",
    "                'y_center': y_center,\n",
    "                'width_pixels': car_width_px\n",
    "            })\n",
    "    \n",
    "    # STEP 2.1: For learning phase - detect full car width in entire frame\n",
    "    full_frame_car_for_learning = None\n",
    "    \n",
    "    if plate_detected and plate_distance < DISTANCE_THRESHOLD:\n",
    "        for box in vehicle_results[0].boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            plate_x1, plate_y1, plate_x2, plate_y2 = plate_box\n",
    "            plate_center_x = (plate_x1 + plate_x2) / 2\n",
    "            plate_center_y = (plate_y1 + plate_y2) / 2\n",
    "            \n",
    "            if x1 <= plate_center_x <= x2 and y1 <= plate_center_y <= y2:\n",
    "                full_car_width_pixels = abs(x2 - x1)\n",
    "                full_frame_car_for_learning = {\n",
    "                    'bbox': (x1, y1, x2, y2),\n",
    "                    'width_pixels': full_car_width_pixels\n",
    "                }\n",
    "                break\n",
    "    \n",
    "    # STEP 2.5: Prioritize vehicles in bottom 70% of ROI + largest bbox\n",
    "    vehicle_box = None\n",
    "    vehicle_detected = False\n",
    "    car_width_pixels = 0\n",
    "    \n",
    "    if vehicle_detections:\n",
    "        roi_height = int(frame_height * ROI_BOTTOM_Y_RATIO) - int(frame_height * ROI_TOP_Y_RATIO)\n",
    "        min_y_threshold = int(frame_height * ROI_TOP_Y_RATIO) + (roi_height * (1 - ROI_BOTTOM_PRIORITY_RATIO))\n",
    "        \n",
    "        priority_vehicles = [v for v in vehicle_detections if v['y_center'] >= min_y_threshold]\n",
    "        \n",
    "        if not priority_vehicles:\n",
    "            priority_vehicles = vehicle_detections\n",
    "        \n",
    "        best_vehicle = max(priority_vehicles, key=lambda v: v['area'])\n",
    "        vehicle_box = best_vehicle['bbox']\n",
    "        car_width_pixels = best_vehicle['width_pixels']\n",
    "        vehicle_detected = True\n",
    "    \n",
    "    # STEP 3: Match with existing vehicles using IoU\n",
    "    matched_vehicle_id = None\n",
    "    \n",
    "    if vehicle_detected:\n",
    "        best_iou = 0\n",
    "        best_match_id = None\n",
    "        \n",
    "        for vid, vtracker in tracked_vehicles.items():\n",
    "            if vtracker.last_bbox is not None:\n",
    "                iou = calculate_iou(vehicle_box, vtracker.last_bbox)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match_id = vid\n",
    "        \n",
    "        if best_iou > IOU_THRESHOLD:\n",
    "            matched_vehicle_id = best_match_id\n",
    "            current_vehicle_id = best_match_id\n",
    "        else:\n",
    "            # Graceful handoff: if only one vehicle and recently seen, continue tracking\n",
    "            if len(tracked_vehicles) == 1:\n",
    "                last_vehicle_id = list(tracked_vehicles.keys())[0]\n",
    "                frames_since_last = frame_count - last_seen_frame[last_vehicle_id]\n",
    "                \n",
    "                if frames_since_last < 90:\n",
    "                    matched_vehicle_id = last_vehicle_id\n",
    "                    current_vehicle_id = last_vehicle_id\n",
    "                else:\n",
    "                    matched_vehicle_id = next_vehicle_id\n",
    "                    tracked_vehicles[matched_vehicle_id] = DistanceTracker()\n",
    "                    next_vehicle_id += 1\n",
    "                    current_vehicle_id = matched_vehicle_id\n",
    "            else:\n",
    "                matched_vehicle_id = next_vehicle_id\n",
    "                tracked_vehicles[matched_vehicle_id] = DistanceTracker()\n",
    "                next_vehicle_id += 1\n",
    "                current_vehicle_id = matched_vehicle_id\n",
    "    \n",
    "    # STEP 4: Calculate distance and update tracker\n",
    "    if matched_vehicle_id:\n",
    "        last_seen_frame[matched_vehicle_id] = frame_count\n",
    "        tracker = tracked_vehicles[matched_vehicle_id]\n",
    "        tracker.last_bbox = vehicle_box\n",
    "        \n",
    "        final_distance = None\n",
    "        final_box = None\n",
    "        detection_method = \"\"\n",
    "        learned_car_width = None\n",
    "        \n",
    "        calibrated_car_width = tracker.get_calibrated_car_width()\n",
    "        \n",
    "        # Hybrid detection logic\n",
    "        if plate_detected and plate_distance < DISTANCE_THRESHOLD:\n",
    "            final_distance = plate_distance\n",
    "            final_box = plate_box\n",
    "            detection_method = f\"PLATE {plate_distance:.1f}m\"\n",
    "            \n",
    "            # Learn car width from full frame detection if available\n",
    "            if full_frame_car_for_learning:\n",
    "                full_car_width_pixels = full_frame_car_for_learning['width_pixels']\n",
    "                learned_car_width = (full_car_width_pixels * plate_distance * 100) / FOCAL_LENGTH_PIXELS\n",
    "                if MIN_CAR_WIDTH_CM <= learned_car_width <= MAX_CAR_WIDTH_CM:\n",
    "                    detection_method = f\"PLATE {plate_distance:.1f}m [LEARNING]\"\n",
    "            elif vehicle_detected and car_width_pixels > 0:\n",
    "                learned_car_width = (car_width_pixels * plate_distance * 100) / FOCAL_LENGTH_PIXELS\n",
    "                if MIN_CAR_WIDTH_CM <= learned_car_width <= MAX_CAR_WIDTH_CM:\n",
    "                    detection_method = f\"PLATE {plate_distance:.1f}m [LEARNING]\"\n",
    "            \n",
    "        elif plate_detected and plate_distance >= DISTANCE_THRESHOLD:\n",
    "            if vehicle_detected and car_width_pixels > 0:\n",
    "                vehicle_distance = (calibrated_car_width * FOCAL_LENGTH_PIXELS) / car_width_pixels / 100\n",
    "                final_distance = vehicle_distance\n",
    "                final_box = vehicle_box\n",
    "                width_status = \"LEARNED\" if len(tracker.calibrated_widths) > 0 else \"DEFAULT\"\n",
    "                detection_method = f\"CAR {vehicle_distance:.1f}m [{width_status}: {calibrated_car_width:.0f}cm]\"\n",
    "            else:\n",
    "                final_distance = plate_distance\n",
    "                final_box = plate_box\n",
    "                detection_method = f\"PLATE {plate_distance:.1f}m (far)\"\n",
    "            \n",
    "        elif not plate_detected and vehicle_detected and car_width_pixels > 0:\n",
    "            vehicle_distance = (calibrated_car_width * FOCAL_LENGTH_PIXELS) / car_width_pixels / 100\n",
    "            final_distance = vehicle_distance\n",
    "            final_box = vehicle_box\n",
    "            width_status = \"LEARNED\" if len(tracker.calibrated_widths) > 0 else \"DEFAULT\"\n",
    "            detection_method = f\"CAR {vehicle_distance:.1f}m [{width_status}: {calibrated_car_width:.0f}cm]\"\n",
    "        \n",
    "        # Check for distance jump before updating\n",
    "        if final_distance and tracker.check_distance_jump(final_distance):\n",
    "            del tracked_vehicles[matched_vehicle_id]\n",
    "            if matched_vehicle_id in last_seen_frame:\n",
    "                del last_seen_frame[matched_vehicle_id]\n",
    "            if matched_vehicle_id == current_vehicle_id:\n",
    "                current_vehicle_id = None\n",
    "            matched_vehicle_id = None\n",
    "        elif final_distance:\n",
    "            tracker.update(final_distance, final_box, True, learned_car_width)\n",
    "        else:\n",
    "            tracker.update(None, None, True, None)\n",
    "        \n",
    "        # Apply filters\n",
    "        if matched_vehicle_id and final_distance and final_distance > ONCOMING_MIN_DISTANCE and tracker.is_approaching():\n",
    "            del tracked_vehicles[matched_vehicle_id]\n",
    "            if matched_vehicle_id in last_seen_frame:\n",
    "                del last_seen_frame[matched_vehicle_id]\n",
    "            if matched_vehicle_id == current_vehicle_id:\n",
    "                current_vehicle_id = None\n",
    "            matched_vehicle_id = None\n",
    "        \n",
    "        elif matched_vehicle_id and tracker.is_crossing_traffic():\n",
    "            del tracked_vehicles[matched_vehicle_id]\n",
    "            if matched_vehicle_id in last_seen_frame:\n",
    "                del last_seen_frame[matched_vehicle_id]\n",
    "            if matched_vehicle_id == current_vehicle_id:\n",
    "                current_vehicle_id = None\n",
    "            matched_vehicle_id = None\n",
    "        \n",
    "        # Draw vehicle if minimum dwell time reached\n",
    "        if matched_vehicle_id:\n",
    "            smoothed_distance = tracker.get_smoothed_distance()\n",
    "            \n",
    "            if smoothed_distance and tracker.consecutive_frames >= MIN_DWELL_FRAMES and final_box:\n",
    "                x1, y1, x2, y2 = final_box\n",
    "                \n",
    "                cv2.rectangle(display_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 3)\n",
    "                \n",
    "                vehicle_label = f\"Vehicle #{matched_vehicle_id}\"\n",
    "                distance_label = f\"{smoothed_distance:.1f}m\"\n",
    "                \n",
    "                cv2.putText(display_frame, vehicle_label, (int(x1), int(y1)-60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(display_frame, distance_label, (int(x1), int(y1)-35),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(display_frame, detection_method, (int(x1), int(y1)-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "                \n",
    "                # Export to CSV\n",
    "                csv_data.append({\n",
    "                    'frame': frame_count,\n",
    "                    'timestamp_sec': frame_count / fps,\n",
    "                    'vehicle_id': matched_vehicle_id,\n",
    "                    'distance_m': smoothed_distance,\n",
    "                    'detection_method': detection_method.split()[0],  # PLATE or CAR\n",
    "                    'consecutive_frames': tracker.consecutive_frames\n",
    "                })\n",
    "    \n",
    "    # Status overlay\n",
    "    status = f\"Frame: {frame_count} | Device: {device.upper()}\"\n",
    "    cv2.putText(display_frame, status, (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    out.write(display_frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Export CSV data\n",
    "if csv_data:\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Output video: {output_video_path}\")\n",
    "    print(f\"Output CSV: {output_csv_path}\")\n",
    "    print(f\"Total vehicles tracked: {next_vehicle_id - 1}\")\n",
    "    print(f\"CSV records exported: {len(csv_data)}\")\n",
    "else:\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Output video: {output_video_path}\")\n",
    "    print(f\"Total vehicles tracked: {next_vehicle_id - 1}\")\n",
    "    print(\"Warning: No CSV data exported (no vehicles met minimum dwell time)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
